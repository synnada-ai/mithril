# Copyright 2022 Synnada, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

from types import UnionType
from typing import Self, TypeVar, overload

from ...core import Constant
from ...utils.utils import OrderedSet, find_dominant_type
from ..common import (
    NOT_AVAILABLE,
    NOT_GIVEN,
    TBD,
    Connect,
    Connection,
    ConnectionData,
    ConnectionType,
    ExtendTemplate,
    IOHyperEdge,
    IOKey,
    KeyType,
    MainValueType,
    NullConnection,
    Scalar,
    ShapeRepr,
    ShapeTemplateType,
    Tensor,
    ToBeDetermined,
    Updates,
    Variadic,
    _get_summary_shapes,
    _get_summary_types,
    get_summary,
)
from ..utils import define_unique_names
from .base import ExtendInfo
from .essential_primitives import (
    Absolute,
    Add,
    Divide,
    Equal,
    FloorDivide,
    Greater,
    GreaterEqual,
    Length,
    Less,
    LessEqual,
    LogicalAnd,
    LogicalNot,
    LogicalOr,
    LogicalXOr,
    MatrixMultiply,
    Max,
    Mean,
    Min,
    Minus,
    Multiply,
    NotEqual,
    Power,
    PrimitiveSlice,
    Prod,
    Reshape,
    ScalarItem,
    Shape,
    ShiftLeft,
    ShiftRight,
    Size,
    Sqrt,
    Subtract,
    Sum,
    TensorItem,
    TensorSlice,
    TensorToList,
    ToList,
    ToTensor,
    ToTuple,
    Transpose,
    Variance,
)
from .primitive import BaseModel, PrimitiveModel

__all__ = ["Model"]

ops_table: dict[str, type[PrimitiveModel]] = {
    "add": Add,
    "sub": Subtract,
    "div": Divide,
    "fdiv": FloorDivide,
    "mul": Multiply,
    "pow": Power,
    "matmul": MatrixMultiply,
    "shape": Shape,
    "reshape": Reshape,
    "len": Length,
    "size": Size,
    "tensor": ToTensor,
    "list": TensorToList,
    "mean": Mean,
    "sqrt": Sqrt,
    "sum": Sum,
    "max": Max,
    "min": Min,
    "abs": Absolute,
    "prod": Prod,
    "var": Variance,
    "gt": Greater,
    "ge": GreaterEqual,
    "lt": Less,
    "le": LessEqual,
    "eq": Equal,
    "ne": NotEqual,
    "not": LogicalNot,
    "and": LogicalAnd,
    "or": LogicalOr,
    "xor": LogicalXOr,
    "lshift": ShiftLeft,
    "rshift": ShiftRight,
    "minus": Minus,
    "transpose": Transpose,
}


coercion_table: dict[tuple[str, type[Tensor] | type[Scalar]], type[PrimitiveModel]] = {
    ("item", Tensor): TensorItem,
    ("item", Scalar): ScalarItem,
    ("slice", Tensor): TensorSlice,
    ("slice", Scalar): PrimitiveSlice,
}

type_conversion_map: dict[
    tuple[type[Tensor] | type[Scalar], type[Tensor] | type[Scalar]],
    type[ToTensor] | type[TensorToList] | None,
] = {
    (Scalar, Tensor): ToTensor,
    (Tensor, Scalar): TensorToList,
    (Tensor, Tensor): None,
    (Scalar, Scalar): None,
}


class Model(BaseModel):
    def __init__(
        self, formula_key: str | None = None, enforce_jit: bool = True
    ) -> None:
        self.passive_output = None
        self.main_primitive = None
        self.dag: dict[BaseModel, dict[str, ConnectionData]] = {}
        self.inter_key_count = 0
        self.formula_key = formula_key
        super().__init__(enforce_jit=enforce_jit)

    def create_key_name(self):
        self.inter_key_count += 1
        return "$" + str(self.inter_key_count)

    def create_connection(
        self, metadata: IOHyperEdge, key: str | None = None
    ) -> ConnectionData:
        # If key is not provided, create a new key name and
        # label it as auto-generated.
        if is_key_autogenerated := key is None:
            key = self.create_key_name()

        con = self._create_connection(metadata, key, is_key_autogenerated)

        if not is_key_autogenerated:
            # Set key_origin into metadata
            metadata.key_origin = key
            setattr(self, key, con)

        return con.data

    def set_outputs(self, *args: str | Connection, **kwargs: str | Connection) -> None:
        if self.parent is not None:
            raise Exception("Child model's outputs cannot be set.")
        # Convert all args and kwargs to tuple.
        # Convert all args and kwargs to tuple.
        pairs = tuple([(None, arg) for arg in args]) + tuple(kwargs.items())

        for pair in pairs:
            new_name, name = pair
            metadata = self.conns.extract_metadata(name)

            # Check the connection is valid.
            if (conn_data := self.conns.get_con_by_metadata(metadata)) is None:
                raise KeyError("Requires valid key or Connection to set output!")

            # Check if given metadata is already an output.
            if conn_data in self.conns.output_connections:
                raise KeyError(f"'{conn_data.key}' key is already set as output!")

            if conn_data in self.conns.input_connections:
                raise KeyError("Input of the overall model cannot be set as output.")

            # Autogenerated keys can not be set directly as output without a name.
            if new_name is None and conn_data.key.startswith("$"):
                raise KeyError(
                    "Autogenerated keys can only be set as output if"
                    " a name is provided for the connection as keyworded argument."
                )

            if new_name is None:  # Non-named connections.
                # Set connection as output and update dependency map.
                self.conns.set_connection_type(conn_data, KeyType.OUTPUT)
                self.dependency_map._update_globals(OrderedSet({conn_data}))

            else:  # Named connections.
                # Create new output connection with given key name.

                data: Tensor | Scalar = (
                    Scalar(metadata.data._type)
                    if isinstance(metadata.data, Scalar)
                    else Tensor(metadata.data.shape, metadata.data._type, None, None)
                )

                new_conn = self.create_connection(IOHyperEdge(data), new_name)

                # Set connection as output and update dependency map.
                self.conns.set_connection_type(new_conn, KeyType.OUTPUT)

                # Merge new_conn with given connection.
                self.merge_connections(new_conn, conn_data)

    def _set_value(self, key: ConnectionData, value: MainValueType) -> Updates:
        if isinstance(key.metadata.data, Tensor) and value is not TBD:
            extend_value: MainValueType | IOKey = value
            # If ToTensor output key is reserved key, rename it.
            if key.conn.key == "input":
                self.inter_key_count += 1
                new_conn_name = "$" + str(self.inter_key_count)

                # Update connections
                self.conns._connection_dict[KeyType.INPUT][new_conn_name] = (
                    self.conns._connection_dict[KeyType.INPUT].pop(key.conn.key)
                )
                # Update connection key
                key.key = new_conn_name
                extend_value = IOKey("input", value)

            # Scalar to Tensor conversion is required.
            model = ToTensor()
            assert isinstance(self.canonical_input, Connection)
            preserved_canonical_input: ConnectionData | None = self.canonical_input.data
            if key == self.canonical_input.data:
                preserved_canonical_input = None

            self.extend(model, input=extend_value, output=key.conn)
            if preserved_canonical_input is not None:
                self.set_canonical_input(preserved_canonical_input.conn)
            return Updates()
        return super()._set_value(key, value)

    def _check_multi_write(
        self,
        local_input: bool,
        local_connection: ConnectionData,
        connection: ConnectionData,
    ) -> None:
        conn_is_output = (
            self.dependency_map._local_output_dependency_map.get(connection, None)
            is not None
        )
        if local_connection.key in self.conns.all and connection.key in self.conns.all:
            local_conn_is_output = (
                self.dependency_map._local_output_dependency_map.get(
                    local_connection, None
                )
                is not None
            )
            if (
                conn_is_output
                and local_conn_is_output
                and local_connection.key != connection.key
            ):
                # Check if 2 connections are part of main model. If it is the case,
                # We expect at least one of them is not an input of the main model,
                # otherwise condition is Multi-write error
                raise Exception(
                    "Given connections are both output connections. Multi-write error!"
                )

        if conn_is_output and not local_input:
            # Check if 2 connections are both output of any models.
            raise Exception(
                "Given connections are both output connections. Multi-write error!"
            )

        # If key is an input of the model and has a value and also
        # con_obj is a global input, then they must have same value or
        # local connection has Ellipsis as value. If con_obj is not a
        # global input, raise error.
        # Note that Tensor type connections can not have any value
        # in logical models.
        if isinstance((data := local_connection.metadata.data), Scalar):
            pair = [connection.metadata.data, data]
            check_data, other = pair[local_input], pair[not local_input]
            if check_data.value is not TBD and check_data.value != other.value:
                raise ValueError("Multi-write detected for a valued input connection!")

    def _add_connection(
        self,
        model: BaseModel,
        local_key: str,
        given_connection: ConnectionType,
        expose=None,
    ) -> tuple[ConnectionData, Updates]:
        updates = Updates()
        outer_key, con_obj = None, None
        is_input = local_key in model._input_keys
        local_connection = model.conns.get_connection(local_key)
        assert local_connection is not None, "Connection is not found!"
        # Flags for use in required operations.
        create_connection = None
        set_value: MainValueType | NullConnection = NOT_GIVEN  # value can be anything.
        match_connection = None

        if isinstance(
            given_connection, MainValueType | NullConnection
        ):  # or given_connection == NOT_GIVEN:
            # Immediate values can be provided only for inputs.
            # if given_connection != NOT_GIVEN:
            if isinstance(given_connection, MainValueType):
                set_value = given_connection

            if expose is None:
                expose = is_input
            create_connection = True

        elif isinstance(given_connection, str):
            # Connection is given as str.
            outer_key = given_connection
            if (con_obj := self.conns.get_connection(given_connection)) is None:
                expose = is_input
                create_connection = True  # Create new connection.
            else:
                # Connection match is required.
                match_connection = True

        elif isinstance(given_connection, ConnectionData):
            # Connection is given as a Connection object.
            # TODO: maybe use directly connections
            if (
                con_obj := self.conns.get_con_by_metadata(given_connection.metadata)
            ) is None:
                raise KeyError("Requires accessible connection to be processed!")

            if given_connection in model.conns.all.values():
                raise ValueError(
                    f"Given connection '{given_connection.key}' should not belong "
                    "to the extending model!"
                )

            outer_key = con_obj.key
            expose = outer_key in self.conns.output_keys and not is_input
            match_connection = True

        else:
            raise TypeError("Requires valid connection type!")

        # Name "input" can only be used for input connections.
        if not is_input and outer_key == "input":
            raise KeyError(
                "The key 'input' is a reserved key which could not be used for "
                "internal keys."
            )

        # If connection is not created yet, create it.
        if create_connection:
            con_obj = self.create_connection(local_connection.metadata, outer_key)

        # Inherit submodel connections dict
        self.conns.connections_dict.setdefault(local_connection.metadata, set())
        self.conns.connections_dict[local_connection.metadata] |= (
            model.conns.connections_dict.pop(local_connection.metadata, set())
        )

        # If any value provided, set.
        assert con_obj is not None
        if not isinstance(set_value, NullConnection):
            updates |= con_obj.metadata.data.set_value(set_value)

        # Check multi-write error for con_obj.
        self._check_multi_write(is_input, local_connection, con_obj)

        # If match required, perform.
        if match_connection is not None:
            local_key_origin = local_connection.metadata.key_origin
            updates |= self._match_hyper_edges(
                con_obj.metadata, local_connection.metadata
            )
            # If local_connection is an output of the model,
            # update con_obj "key_origin" with local_connection's key_origin.
            if (
                not is_input
                and outer_key not in self.conns.output_keys
                or con_obj.metadata.key_origin is None
            ):
                con_obj.metadata.key_origin = local_key_origin

        # Set connection as input, output or internal based on expose and is_input flag.
        if is_input:
            if expose and outer_key not in self._input_keys:
                self.conns.set_connection_type(con_obj, KeyType.INPUT)
        else:
            if expose and outer_key not in self.conns.output_keys:
                self.conns.set_connection_type(con_obj, KeyType.OUTPUT)
            elif not expose and outer_key not in self.conns.internal_keys:
                self.conns.set_connection_type(con_obj, KeyType.INTERNAL)

        return con_obj, updates

    def _unroll_template(
        self, template: ExtendTemplate, joint_type: type[Tensor] | type[Scalar]
    ) -> ConnectionData:
        if template.output_connection is None:
            # Initialize all default init arguments of model as "..." other
            # than the keys in template.defaults, in order to provide
            # given connections to the model after it is created.
            # If we don't do that, it will throw error because of
            # re-setting a Tensor or Scalar value again in extend.
            if (model_type := ops_table.get(template.model)) is None:
                model_config = template.model, joint_type
                model_type = coercion_table.get(model_config)

            assert (
                model_type is not None
            ), "given model is not found in the ops_table or coercion_table"

            init_fun = model_type.__init__

            # "self" argument is common for all models, Exclude it by
            # starting co_varnames from 1st index.
            default_args = init_fun.__code__.co_varnames[
                1 : init_fun.__code__.co_argcount
            ]
            default_args_dict = {
                key: TBD for key in default_args if key not in template.defaults
            }

            # TODO: Reconsider type ignore!
            model: PrimitiveModel = model_type(**default_args_dict)  # type: ignore
            connections: list[ConnectionType] = []
            for idx, connection in enumerate(template.connections):
                if isinstance(connection, ExtendTemplate):
                    conn = model.conns.get_connection(list(model._input_keys)[idx])
                    assert conn is not None
                    conn_type = conn.metadata.data.__class__
                    connections.append(
                        self._unroll_template(connection, conn_type).conn
                    )
                else:
                    assert isinstance(
                        connection, ConnectionType
                    )  # TODO: check if needed
                    connections.append(connection)
            self.extend(
                model,
                **{
                    local_key: outer_con
                    for local_key, outer_con in zip(
                        model._input_keys, connections, strict=False
                    )
                },
            )

            valued_constants: set[ConnectionData] = set()
            for local_key, outer_con in zip(
                model._input_keys, connections, strict=False
            ):
                if isinstance(outer_con, MainValueType) and outer_con is not TBD:
                    conn = model.conns.get_connection(local_key)
                    assert conn is not None
                    conn_data = conn.metadata
                    global_conn_data = self.conns.get_con_by_metadata(conn_data)
                    assert global_conn_data is not None
                    self.conns.set_connection_type(global_conn_data, KeyType.INTERNAL)
                    valued_constants.add(global_conn_data)
            self.dependency_map._update_globals(OrderedSet(valued_constants))

            template.output_connection = model.conns.get_connection("output")
            assert template.output_connection is not None
        return template.output_connection

    def merge_connections(
        self, connection1: ConnectionData, connection2: ConnectionData
    ) -> Updates:
        # This method is used if there is 2 Connection objects to represent same Edge.
        # In this case, connection2 is updated with connection1's data and it is removed
        # from dag, dependency_map, self attribute (if exists) and Connections object.

        main_connection1 = self.conns.get_con_by_metadata(connection1.metadata)
        main_connection2 = self.conns.get_con_by_metadata(connection2.metadata)

        if (
            main_connection1 is None
            or main_connection2 is None
            or main_connection1 == main_connection2
        ):
            return Updates()

        # Remove main_connection2 from connections dict
        con1_key = main_connection1.key

        if connection2 in self.conns.output_connections:
            if con1_key not in self.conns.output_keys:
                self.conns.set_connection_type(connection1, KeyType.OUTPUT)
            if con1_key in self._input_keys:
                self.conns.set_connection_type(main_connection1, KeyType.INTERNAL)
        elif (
            main_connection2 in self.conns.internal_connections
            and con1_key in self._input_keys
        ):
            self.conns.set_connection_type(main_connection1, KeyType.INTERNAL)

        # Switch all connection2 objects with connection1 object in current dag.
        for m, m_info in self.dag.items():
            local_conns = m.conns.get_cons_by_metadata(main_connection2.metadata)
            if local_conns is None:
                continue

            for local_conn in local_conns:
                if m_info.get(local_conn.key) is not None:
                    self.dag[m][local_conn.key] = main_connection1

        # Update dependecy map, we need to update only local maps
        for (
            o_conn,
            key_info,
        ) in self.dependency_map._local_output_dependency_map.items():
            if main_connection2 in key_info[1]:
                self.dependency_map._local_output_dependency_map[o_conn][1].remove(
                    main_connection2
                )
                self.dependency_map._local_output_dependency_map[o_conn][1].add(
                    main_connection1
                )

        if main_connection2 in self.dependency_map._local_output_dependency_map:
            self.dependency_map._local_output_dependency_map[main_connection1] = (
                self.dependency_map._local_output_dependency_map.pop(main_connection2)
            )

        if main_connection2 in self.dependency_map._local_input_dependency_map:
            old_dependencies = self.dependency_map._local_input_dependency_map.pop(
                main_connection2
            )
            self.dependency_map._local_input_dependency_map.setdefault(
                main_connection1, old_dependencies
            )
            for dependecy in old_dependencies:
                if (
                    dependecy
                    not in self.dependency_map._local_input_dependency_map[
                        main_connection1
                    ]
                ):
                    self.dependency_map._local_input_dependency_map[
                        main_connection1
                    ].append(dependecy)

        self.dependency_map.merge_global_connections(main_connection1, main_connection2)
        self.dependency_map.merge_global_caches(main_connection1, main_connection2)
        updates = self._match_hyper_edges(
            main_connection1.metadata, main_connection2.metadata
        )

        self.conns.remove_connection(main_connection2)

        main_connection2.key = main_connection1.key
        main_connection2.is_key_autogenerated = main_connection1.is_key_autogenerated
        return updates

    @overload
    def handle_auto_conversion(
        self,
        key_type: type[Tensor] | type[Scalar],
        is_input: bool,
        connection: IOKey | Connect | ConnectionData,
        updates: Updates,
    ) -> ConnectionData: ...
    @overload
    def handle_auto_conversion(  # type: ignore[overload-cannot-match] # mypy import bug
        self,
        key_type: type[Tensor] | type[Scalar],
        is_input: bool,
        connection: ConnectionType | tuple[ConnectionType, ...] | list[ConnectionType],
        updates: Updates,
    ) -> None | ConnectionData: ...

    def handle_auto_conversion(
        self,
        key_type: type[Tensor] | type[Scalar],
        is_input: bool,
        connection: ConnectionType | tuple[ConnectionType, ...] | list[ConnectionType],
        updates: Updates,
    ) -> ConnectionType:
        connection_type: type[Tensor] | type[Scalar] | None = None
        if isinstance(connection, MainValueType) and connection is not TBD:
            connection_type = Scalar

        elif isinstance(connection, ConnectionData):
            connection_type = connection.metadata.data.__class__

        # elif (
        #     isinstance(connection, str)
        #     and (data := self.conns.get_data(connection)) is not None
        # ):
        elif (
            isinstance(connection, str)
            and (_conn := self.conns.get_connection(connection)) is not None
        ):
            data = _conn.metadata.data
            connection_type = data.__class__

        elif isinstance(connection, IOKey):
            # Return NOTGIVEN if IOKey has value, name and expose
            # attributes as their default values.
            existing_conn = None
            if (
                connection._name is None
                and connection._value == NOT_GIVEN
                and connection._expose is None
            ):
                return NOT_GIVEN

            set_type = connection._type
            set_value = connection._value
            # is_value_given = isinstance(set_value, MainValueType)
            is_value_given = not isinstance(set_value, ToBeDetermined | NullConnection)
            if connection._name is not None:
                existing_conn = self.conns.get_connection(connection._name)
            if (
                connection._name is not None
                and existing_conn is not None
                and existing_conn.key in self.conns._connection_dict[KeyType.OUTPUT]
                and not connection._expose
            ):
                raise ValueError(
                    "Given IOKey is already exists as an output key and it is "
                    "exposed. IOKey expose flag cannot be 'False'!"
                )

            if (
                is_input
                and existing_conn is None
                and not (is_value_given or connection._expose)
            ):
                raise ValueError(
                    "Expose flag cannot be false when no value is provided for "
                    "input keys!"
                )

            if (key_type is Scalar) and (connection._shape is not None):
                raise KeyError("Shape cannot be set for scalar type values")

            # Create data object based on given_value or given key_type.
            if is_value_given:
                assert isinstance(set_value, MainValueType)
                data = Scalar(value=set_value)

            elif key_type == Scalar:
                if set_type is None:
                    set_type = MainValueType
                data = Scalar(possible_types=set_type)

            else:
                if set_type is None:
                    set_type = int | float | bool
                shape_node = ShapeRepr(root=Variadic()).node
                data = Tensor(shape_node, set_type, None, None)

            # Determine connection type.
            if connection._expose:
                conn_type = KeyType.INPUT if is_input else KeyType.OUTPUT
            else:
                conn_type = KeyType.INTERNAL

            # Existing connection type
            existing_conn_type = None
            if existing_conn is not None:
                if existing_conn.key in self.conns._connection_dict[KeyType.INPUT]:
                    existing_conn_type = KeyType.INPUT
                elif existing_conn.key in self.conns._connection_dict[KeyType.OUTPUT]:
                    existing_conn_type = KeyType.OUTPUT
                else:
                    existing_conn_type = KeyType.INTERNAL

            # If the existing connection is internal (i.e., an output of a primitive)
            # and the connection type is input, the user wants to expose this
            # connection, then conn_type should be output.
            if existing_conn_type is KeyType.INTERNAL and conn_type is KeyType.INPUT:
                conn_type = KeyType.OUTPUT

            # Create new connection using data object.
            if existing_conn is None:
                new_conn = self.create_connection(IOHyperEdge(data), connection._name)
            else:
                assert connection._name is not None
                _new_conn = self.conns.get_connection(connection._name)
                assert _new_conn is not None, "Connection is not found!"
                new_conn = _new_conn
                if not isinstance(connection._value, NullConnection):
                    self.set_values({new_conn.conn: connection._value})
                if connection._shape is not None:
                    self.set_shapes({new_conn.conn: connection._shape})
                if connection._type is not None:
                    self.set_types({new_conn.conn: connection._type})

            self.conns.set_connection_type(new_conn, conn_type)

            # Perform conversion if required.
            return self.handle_auto_conversion(
                key_type, is_input, new_conn, updates=updates
            )

        elif isinstance(connection, Connect):
            connections: set[ConnectionData] = set()
            output_connection = None  # A connection which is an output of any model.
            base_conn = None
            # First convert all connections in Connect into Connection.
            for conn in connection.connections:
                if isinstance(conn, str):
                    con_obj = self.conns.get_connection(conn)
                else:
                    con_obj = self.conns.get_con_by_metadata(conn.metadata)

                # Connections in Connect object must be accessible in self.
                if con_obj is None:
                    raise KeyError("Requires accessible connection to be processed!")
                elif con_obj not in self.conns.input_connections:
                    if output_connection is not None:
                        raise KeyError(
                            "Connect object can not have more than one output "
                            "connection. Multi-write error!"
                        )
                    output_connection = con_obj
                connections.add(con_obj)

            # In case of Connect object has an IOKey, first create this connection.
            if isinstance(connection.key, IOKey):
                # Immediate values can not be assigned to output connections.
                if output_connection is not None and connection.key._value != NOT_GIVEN:
                    raise ValueError(
                        "Connect object can not have both an output connection and "
                        "a value. Multi-write error!"
                    )

                if output_connection is not None:
                    data_type = output_connection.metadata.data.__class__
                    is_conn_input = False

                elif connection.key._value not in (TBD, NOT_GIVEN):
                    data_type = Scalar
                    is_conn_input = True

                else:
                    # All connections in Connect object must have same type.
                    types: set[type[Scalar] | type[Tensor]] = {
                        _conn.metadata.data.__class__ for _conn in connections
                    }
                    if len(types) > 1:
                        raise TypeError("Connected connections are not of same type!")
                    data_type = (
                        types.pop() if types else key_type
                    )  # If no connection exists, take key_type.
                    is_conn_input = True

                # NOTE: Temporarily set IOKey expose flag to True in order to avoid
                # possible errors. For example if user sets expose = False and
                # performs an extension from input keys, it throws an error like "input
                # keys are always exposed". We can bypass this error by setting expose
                # flag to its default value (True) and reset it to the desired type
                # after base_conn is created.
                original_expose = connection.key._expose
                connection.key._expose = True

                # Since we provide data type of connection, base_conn always be
                # the connection
                # created for provided IOKey.
                base_conn = self.handle_auto_conversion(
                    data_type, is_conn_input, connection.key, updates
                )

                # If connected objects are all input connections, expose flag can not
                # set as False.
                if not original_expose and is_conn_input and is_input:
                    raise Exception("Input keys are always exposed!")

                # Revert expose flag to its original state and set connection type
                # based on it. NOTE: If base connection is merged with an already
                # exposed output connection,it will automatically set as output
                # connection in merge_connections method.
                if not original_expose:
                    self.conns.set_connection_type(base_conn, KeyType.INTERNAL)
                elif not is_input:
                    self.conns.set_connection_type(base_conn, KeyType.OUTPUT)

                # Reset expose flag to its original state.
                connection.key._expose = original_expose

                if base_conn == NOT_GIVEN:
                    base_conn = next(iter(connections), None)

            else:
                # Choose one of the connections as base connection. If any
                # internal connection occurs, choose it as base connection.
                if output_connection is not None:
                    base_conn = output_connection
                else:
                    base_conn = next(iter(connections), None)

            # Connect object must have at least one connection.
            if base_conn is None:
                raise Exception("Connect object must have at least one connection!")

            # Iterate over all connections in Connect object and merge them with con_obj
            for con in connections:
                # If any connection in Connect already connected, skip it:
                if con.metadata != base_conn.metadata:
                    resulting_conn = self.handle_auto_conversion(
                        con.metadata.data.__class__,
                        con in self.conns.input_connections,
                        base_conn,
                        updates=updates,
                    )
                    reference_conn = con
                    other_conn = (
                        resulting_conn if resulting_conn != base_conn else base_conn
                    )

                    self._check_multi_write(is_input, resulting_conn, other_conn)

                    # Update reference and other connections based on their keys'
                    # generation type and name of Connect object if there exists.
                    if not other_conn.is_key_autogenerated:
                        if (
                            connection.key is not None
                            and connection.key._name is not None
                        ) or reference_conn.is_key_autogenerated:
                            reference_conn, other_conn = other_conn, reference_conn
                        elif not reference_conn.is_key_autogenerated:
                            raise KeyError(
                                "Requires a connection to have only one unique key "
                                "name but encountered more!"
                            )

                    updates |= self.merge_connections(reference_conn, other_conn)

            connection_type = base_conn.metadata.data.__class__
            connection = base_conn

        return self.create_connection_model(
            connection_type, key_type, is_input, connection
        )

    T = TypeVar("T", bound=ConnectionType)

    # if connection is a tuple or list, function will always return ConnectionData
    @overload
    def create_connection_model(
        self,
        connection_type: type[Tensor] | type[Scalar] | None,
        key_type: type[Tensor] | type[Scalar],
        is_input: bool,
        connection: tuple[ConnectionType, ...] | list[ConnectionType],
    ) -> ConnectionData: ...

    # if connection_type and key_type are same, function will always
    # return the Connection
    @overload
    def create_connection_model(
        self,
        connection_type: type[Tensor],
        key_type: type[Tensor],
        is_input: bool,
        connection: T,
    ) -> T:
        ...

        # if connection_type and key_type are different, function will
        # always return a ConnectionData

    @overload
    def create_connection_model(  # type: ignore[overload-cannot-match] # mypy import bug
        self,
        connection_type: type[Tensor],
        key_type: type[Scalar],
        is_input: bool,
        connection: ConnectionType | tuple[ConnectionType, ...] | list[ConnectionType],
    ) -> ConnectionData: ...

    # if connection_type and key_type are different, function will
    # always return a ConnectionData
    @overload
    def create_connection_model(  # type: ignore[overload-cannot-match] # mypy import bug
        self,
        connection_type: type[Scalar],
        key_type: type[Tensor],
        is_input: bool,
        connection: ConnectionType | tuple[ConnectionType, ...] | list[ConnectionType],
    ) -> ConnectionData:
        ...

        # if connection_type and key_type are same, function will
        # always return the Connection

    @overload
    def create_connection_model(  # type: ignore[overload-cannot-match] # mypy import bug
        self,
        connection_type: type[Scalar],
        key_type: type[Scalar],
        is_input: bool,
        connection: ConnectionType | tuple[ConnectionType, ...] | list[ConnectionType],
    ) -> ConnectionData: ...

    # if connection_type is None, function will always return the connection
    @overload
    def create_connection_model(
        self,
        connection_type: None,
        key_type: type[Tensor] | type[Scalar],
        is_input: bool,
        connection: T,
    ) -> T: ...

    def create_connection_model(
        self,
        connection_type: type[Tensor] | type[Scalar] | None,
        key_type: type[Tensor] | type[Scalar],
        is_input: bool,
        connection: ConnectionType | tuple[ConnectionType, ...] | list[ConnectionType],
    ) -> (
        ConnectionData
        | ConnectionType
        | tuple[ConnectionType, ...]
        | list[ConnectionType]
    ):
        canonical_input = self.canonical_input
        update_canonical_input = False
        result = connection

        if isinstance(connection, tuple | list):
            # find_dominant_type returns the dominant type in a container.
            # If a container has a value of type Connection or ExtendTemplate
            # we add necessary models. For any type other than Connection,
            # ExtendTemplate, float, int or bool, raise TypeError.
            if (dominant_type := find_dominant_type(connection, raise_error=False)) in [
                ConnectionData,
                ExtendTemplate,
                Connection,
            ]:
                kwargs = {
                    f"input{idx + 1}": item for idx, item in enumerate(connection)
                }
                connection_model = ToTuple if isinstance(connection, tuple) else ToList
                self.extend(conv_model := connection_model(n=len(connection)), **kwargs)

                result = conv_model.conns.get_connection("output")
                assert result is not None
                update_canonical_input = True
            elif dominant_type not in [float, int, bool, slice]:
                raise TypeError(
                    f"{dominant_type} type is not supported for conversion in "
                    "a container!"
                )

        if connection_type is not None:
            coercion_type = (
                (connection_type, key_type) if is_input else (key_type, connection_type)
            )

            if (conversion_model := type_conversion_map[coercion_type]) is not None:
                bridge = conversion_model()
                final_connection = result
                if isinstance(final_connection, ConnectionData):
                    final_connection = final_connection.conn

                if is_input:
                    update_canonical_input = True
                    self.extend(
                        bridge, input=final_connection
                    )  # Take result into account
                    # result = bridge.output.data
                    result = self.conns.get_con_by_metadata(bridge.output.metadata)
                    assert result is not None
                else:
                    self.extend(
                        bridge, output=final_connection
                    )  # Take result into account
                    # result = bridge.input.data
                    result = self.conns.get_con_by_metadata(bridge.input.metadata)
                    assert result is not None
        # Since we add conversion model automatically, cannonical input  may be changed.
        # Reset it to original key if it is still an input key of self.
        if (
            update_canonical_input
            and canonical_input is not NOT_AVAILABLE
            and canonical_input.key in self._input_keys
        ):
            assert isinstance(canonical_input, Connection)
            self.set_canonical_input(canonical_input)
        return result

    def extend(
        self,
        model: Model | PrimitiveModel | BaseModel,
        **kwargs: ConnectionType,
    ):
        # TODO: kwargs -> ConnectionType
        # Check possible errors before the extension.
        model.check_extendability()
        if self.parent is not None:
            raise AttributeError("Child model could not be re-extended!")
        if self == model:
            raise KeyError("Model can not extend with itself!")
        if self._enforce_jit and not model.jittable:
            raise Exception(
                "Model with enforced Jit can not be extended by a non-jittable model! \
                            Jit can be unforced by setting enforce_jit = False"
            )

        model.parent = self
        # Freeze the model.
        model._freeze()

        updates = Updates()

        input_values: set[str] = set()
        output_values: set[str] = set()

        shape_info: dict[str, ShapeTemplateType] = dict()
        type_info: dict[str, type | UnionType] = dict()

        # Check if any Tensor type key is already initialized with a value.
        # This occurs only when a Primitive model having any Tensor type key
        # initialized with a default value is extending the model.
        for input_key in model._input_keys:
            input_conn = model.conns.all.get(input_key)
            assert input_conn is not None, "Connection type is not found!"
            input_data = input_conn.metadata.data
            if (
                isinstance(input_data, Tensor)
                and input_data.temp_value is not None
                # and not isinstance(input_data.value, Constant)
                and input_data.value is not TBD
            ):
                if (
                    (given_value := kwargs.get(input_key)) is not None
                    and given_value not in (TBD, NOT_GIVEN)
                    and given_value != input_data.temp_value
                    and not isinstance(given_value, Constant)
                ):
                    raise ValueError(
                        f"Value of {model.__class__.__name__}'s {input_key} given "
                        f"as {given_value}. But the value is already initialized as "
                        f"{input_data.temp_value}"
                    )
                kwargs[input_key] = input_data.temp_value
                input_data.temp_value = None

        for key, value in kwargs.items():
            # Check if given keys are among model's keys.
            if key not in model._input_keys | model.conns.output_keys:
                raise KeyError(
                    f"Given '{key}' key is not an input or output of "
                    "the model '{model}'"
                )

            # Check proper naming of given keys.
            if isinstance(value, str):
                if key in model._input_keys and not value.isidentifier():
                    raise KeyError(
                        f"Given key name {value} is not a proper identifier string!"
                    )
                elif key in model._input_keys:
                    input_values.add(value)
                else:
                    output_values.add(value)

            elif isinstance(value, Connection):
                # Get ConnectionData if value is Connection type.
                kwargs[key] = value.data

            elif isinstance(value, ExtendTemplate):
                # Unroll ExtendTemplate
                template_conn = model.conns.get_connection(key)
                assert template_conn is not None, "Connection type is not found!"
                kwargs[key] = self._unroll_template(
                    value, type(template_conn.metadata.data)
                )

            elif isinstance(value, MainValueType):
                if key in model.conns.output_keys:
                    raise KeyError(
                        f"{key} key is an output of the model, output values could "
                        "not be set in extend."
                    )

            elif isinstance(value, IOKey):
                # Hold shape information for IOKey type values in order
                # to set all in a bulk after all connections are added.
                if value._shape is not None:
                    shape_info |= {key: value._shape}

                if value._type is not None:
                    type_info[key] = value._type

            elif isinstance(value, NullConnection):
                continue

            elif value is NOT_AVAILABLE:
                raise ValueError(
                    f"Given value for key: '{key}' is not available. "
                    "Probably Canonical input/output connections are used, "
                    "but the model canonical connections is not determined. Please "
                    "provide connection/key explicitly, or set canonical connections."
                )

            elif not isinstance(value, Connect):
                raise KeyError(
                    f"For key: '{key}', given value: '{value}' is not valid!"
                )

            # If any type conversion required for input keys, add it before main extend.
            is_input = key in model._input_keys
            inner_type = model.conns.all[key].metadata.data.__class__
            if (
                updated_conn := self.handle_auto_conversion(
                    inner_type, is_input, kwargs[key], updates
                )
            ) is not None:
                kwargs[key] = updated_conn

        # Check if any cycles occur with namings.
        if common_keys := input_values.intersection(output_values):
            raise KeyError(
                f"Given connections: '{[key for key in common_keys]}' are used both "
                "in input and output keys, which creates cycle!"
            )

        submodel_dag: dict[str, ConnectionData] = {}
        updates = self.constraint_solver.match(model.constraint_solver)

        # Add canonical output if it is not in externel_keys
        external_keys = list(model.external_keys)
        if (
            model.canonical_output is not NOT_AVAILABLE
            and model.canonical_output.key not in external_keys
        ):
            external_keys.append(model.canonical_output.key)

        for local_key in external_keys:
            con_obj, _updates = self._add_connection(
                model, local_key, kwargs.get(local_key, NOT_GIVEN)
            )
            updates |= _updates
            submodel_dag[local_key] = con_obj
            if isinstance(con_obj.metadata.data, Tensor):
                updates.shape_updates.add(con_obj.metadata.data)

        # Replace shape info keys, which are local keys, with global equivalents.
        shape_info = {
            submodel_dag[key].key: template for key, template in shape_info.items()
        }
        type_info = {
            submodel_dag[key].key: template for key, template in type_info.items()
        }
        # Set given shapes.
        self._set_shapes(
            shape_info,
            updates=updates,
        )  # TODO: Should "trace" be set to True?.

        # Set given types.
        self.set_types(type_info)

        model.constraint_solver.clear()
        model.conns.connections_dict = {}

        # Insert to self dag as a FrozenDict.""
        # Since we update dag in merge_connections, we could not use FrozenDict.
        self.dag[model] = model_dag = submodel_dag

        self.dependency_map.add_model_dag(model, model_dag)

        # Update Canonicals
        if isinstance(c_input := model.canonical_input, Connection):
            c_input_obj = self.conns.get_con_by_metadata(c_input.data.metadata)

            if c_input_obj not in self.dependency_map._local_output_dependency_map:
                # Update canonical input with model canonical input
                if c_input_obj is None:
                    self._canonical_input = NOT_AVAILABLE
                else:
                    self._canonical_input = c_input_obj

            elif (
                self._canonical_input
                in self.dependency_map._local_output_dependency_map
            ):
                # Model canonical output used as input than make it None
                self._canonical_input = NOT_AVAILABLE

        if isinstance(c_output := model.canonical_output, Connection):
            c_output_obj = self.conns.get_con_by_metadata(c_output.data.metadata)

            if c_output_obj not in self.dependency_map._local_input_dependency_map:
                # Update canonical output with model canonical output
                if c_output_obj is None:
                    self._canonical_output = NOT_AVAILABLE
                else:
                    self._canonical_output = c_output_obj

            elif (
                self._canonical_output
                in self.dependency_map._local_input_dependency_map
            ):
                # Model canonical output used as input than make it None
                self._canonical_output = NOT_AVAILABLE

        # Update jittablity by using model's jittablity.
        self._jittable &= model.jittable

    # def __add__(self, model: Model | PrimitiveModel):
    #     """This function allows models to be added sequentially via "+=" operator.
    #     There are several conditions for a model to be sequentially added:
    #     if added model has single input, connect that input directly.

    #     Parameters
    #     ----------
    #     model : Model
    #         Other model to be sequentially added.
    #     """
    #     if not (isinstance(model, BaseModel) or isinstance(model, PrimitiveModel)):
    #         raise TypeError("Added element should be a Model type.")
    #     kwargs = {}
    #     if self.canonical_output:
    #         kwargs = {model._canonical_input.key: self.canonical_output}

    #     self.extend(model, **kwargs)
    #     return self

    def __add__(self, info: ExtendInfo | PrimitiveModel | Model) -> Self:
        """This function allows models to be added via "+=" operator.
        There are several conditions for a model to be added:
        if added model has single input, connect that input directly.

        Parameters
        ----------
        model : Model
            Other model to be added.
        """

        model, kwargs = (
            (info._model, info._connections)
            if isinstance(info, ExtendInfo)
            else (info, {})
        )

        if not isinstance(model, BaseModel | PrimitiveModel):
            raise TypeError("Added element should be a Model type.")

        if (
            model._canonical_input is not NOT_AVAILABLE
            and (
                model._canonical_input.key not in kwargs
                or kwargs[model._canonical_input.key] is NOT_GIVEN
            )
            and len(self.dag) > 0
        ):
            kwargs[model._canonical_input.key] = self.canonical_output

        for key, value in kwargs.items():
            _value = value._name if isinstance(value, IOKey) else value

            if isinstance(_value, str) and _value == "":
                if key in model._input_keys:
                    _value = NOT_GIVEN
                else:
                    raise KeyError(
                        "Empty string is not a valid for output connections!"
                    )

                if isinstance(value, IOKey):
                    value._name = None
                else:
                    kwargs[key] = _value

        self.extend(model, **kwargs)
        return self

    __iadd__ = __add__

    @staticmethod
    def _update_key_name(
        new_key, underscored_keys, raw_keys, key_mappings, key_origin, input_set
    ) -> tuple[str, str]:
        # Add underscore if generated key name exists in input keys
        key_prefix = "_"
        # check any of key_prefix + raw_keys[key_origin] in input keys
        flag = True
        while flag:
            flag = False
            for item in raw_keys[key_origin]:
                if key_prefix + key_mappings[item] in input_set | set(
                    key_mappings.values()
                ):
                    key_prefix += "_"
                    flag = True

        new_key = key_prefix + new_key
        underscored_keys.add(key_origin)
        # Update same origin key names that has been previously added.
        for raw_key in raw_keys[key_origin]:
            key_mappings[raw_key] = key_prefix + key_mappings[raw_key]
        raw_keys[key_prefix + key_origin] = raw_keys.pop(key_origin)
        key_origin = key_prefix + key_origin
        return new_key, key_origin

    def _generate_keys(
        self, symbolic=True, include_internals=True, include_outputs=False
    ):
        key_mappings: dict[str, str] = {}
        raw_keys: dict[str, list[str]] = {}
        underscored_keys = set[str]()

        if include_outputs:
            input_set = set(self.external_keys)
            keys = "external_keys"
        else:
            input_set = set(self._input_keys)
            keys = "_input_keys"

        sorted_inputs = [
            self.dag[m][key].key
            for m in self.get_models_in_topological_order()
            for key in getattr(m, keys)
            if self.dag[m][key].key in input_set
        ]
        # TODO: remove duplicate loop traverse
        for key in sorted_inputs:
            new_key = key
            if key[0] != "$":
                continue

            if (
                self._canonical_input is not NOT_AVAILABLE
                and key == self._canonical_input.key
                and "input" not in self._input_keys
            ):
                # Handle canonical input
                new_key = "input"
            else:
                key_origin = self.conns.get_key_origin(key)
                assert key_origin is not None
                # Add prefix until key_origin not in underscored_keys and input_keys.
                while (
                    key_origin in (underscored_keys | self._input_keys)
                    or key_origin == "input"
                ):
                    key_origin = "_" + key_origin

                raw_keys.setdefault(key_origin, [])
                key_idx = len(raw_keys[key_origin])
                if key_idx == 0:
                    # Set key origin as is for the initial key.
                    key_suffix = ""
                else:
                    key_suffix = "_" + str(key_idx)
                    if key_idx == 1:
                        # Update initial key if same key origin is encountered
                        # (add index to initial key).
                        raw_key = raw_keys[key_origin][0]
                        key_mappings[raw_key] = key_mappings[raw_key] + "_0"
                        if key_mappings[raw_key] in self._input_keys:
                            new_key, key_origin = self._update_key_name(
                                new_key,
                                underscored_keys,
                                raw_keys,
                                key_mappings,
                                key_origin,
                                self._input_keys,
                            )

                new_key = key_origin + key_suffix
                if new_key in self._input_keys:
                    new_key, key_origin = self._update_key_name(
                        new_key,
                        underscored_keys,
                        raw_keys,
                        key_mappings,
                        key_origin,
                        self._input_keys,
                    )
                raw_keys[key_origin].append(key)
            key_mappings[key] = new_key

        if include_internals:
            sorted_models = self.get_models_in_topological_order()
            internal_key_mappings: dict[str, str] = {}
            for idx, m in enumerate(sorted_models):
                for key in m.external_keys:
                    outer_conn = self.dag[m][key]
                    outer_key = outer_conn.key
                    if outer_key[0] == "$":
                        # if key is autogenerated, generate a name for the key
                        model_name = m.__class__.__name__
                        key_origin = outer_conn.metadata.key_origin
                        assert key_origin is not None

                        generated_name = (
                            "_" + model_name + "_" + str(idx) + "_" + key_origin
                        )

                        # if key is an output key, directly write it
                        # to the internal_key_mappings
                        # or
                        # if key is an input key, first check if the key
                        # is already in internal_key mappings to avoid
                        # overwrite
                        write_to_internal_key_mappings = (
                            key in m.conns.output_keys
                            or internal_key_mappings.get(
                                outer_key, key_mappings.get(outer_key)
                            )
                            is None
                        )

                        while (
                            generated_name in internal_key_mappings.values()
                            and write_to_internal_key_mappings
                        ):
                            assert key_origin is not None
                            key_origin = "_" + key_origin
                            generated_name = (
                                "_" + model_name + "_" + str(idx) + "_" + key_origin
                            )

                        if write_to_internal_key_mappings:
                            internal_key_mappings[outer_key] = generated_name

            key_mappings = internal_key_mappings | key_mappings
        if symbolic:
            key_mappings = {key: "$" + value for key, value in key_mappings.items()}
        return key_mappings

    def _freeze(self) -> None:
        if (
            self.canonical_output is not NOT_AVAILABLE
            and self.canonical_output.key not in self.conns.output_keys
        ):
            # self.output_keys += (self.canonical_output.key,)
            assert isinstance(self._canonical_output, ConnectionData)
            self.conns._set_connection_type(self._canonical_output, KeyType.OUTPUT)
            # setattr(self, self._canonical_output.key, self.canonical_output)

        self.dependency_map.update_all_keys()

        # Sort and freeze dag
        self.dag = {m: self.dag[m] for m in self.get_models_in_topological_order()}
        if self.formula_key is not None:
            # Must be convertable to primitive.
            assert len(self.conns.output_keys) == 1, (
                "Logical models have altenative primitive implementation must "
                "have only 1 output."
            )

    def summary(
        self,
        shapes: bool = True,
        types: bool = False,
        symbolic: bool = False,
        name: str | None = None,
        alternative_shapes: bool = False,
        uni_cache: dict | None = None,
        var_cache: dict | None = None,
        depth: int = 0,
    ) -> None:
        if uni_cache is None:
            uni_cache = {}
        if var_cache is None:
            var_cache = {}

        type_info = None
        shape_info = None
        # extract relevant information about summary
        dag = self.dag
        name_mappings = define_unique_names(dag)

        # extract model topology
        conn_info = self.extract_connection_info(name_mappings)

        model_shapes = {
            sub_model_name: sub_model.get_shapes(
                uni_cache, var_cache, symbolic, alternative_shapes
            )
            for sub_model, sub_model_name in name_mappings.items()
        }
        if shapes:
            # extract model shapes
            shape_info = _get_summary_shapes(model_shapes, conn_info)

        if types:
            # extract model types
            type_info = _get_summary_types(name_mappings)

        if not name:
            name = self.__class__.__name__

        # construct the table based on relevant information
        table = get_summary(
            conns=conn_info, name=name, shape=shape_info, types=type_info
        )

        table._compile()
        table.display()

        if depth > 0:
            for model, model_name in name_mappings.items():
                kwargs = {
                    "depth": depth - 1,
                    "shapes": shapes,
                    "symbolic": symbolic,
                    "alternative_shapes": alternative_shapes,
                    "name": model_name,
                    "uni_cache": uni_cache,
                    "var_cache": var_cache,
                    "types": types,
                }
                if isinstance(model, PrimitiveModel):
                    kwargs.pop("depth")
                model.summary(**kwargs)

    def extract_connection_info(
        self,
        name_mappings: dict[BaseModel, str],
        data_to_key_map: dict[Tensor | Scalar, list[str]] | None = None,
        data_memo: dict | None = None,
    ):
        conn_info: dict[str, tuple[dict, dict]] = {}
        if self._input_keys:
            if data_to_key_map is None:
                data_to_key_map = {}
            if data_memo is None:
                data_memo = {}
            model_key_map = {}

            # handle the case when model is constructed with += operation. In that case,
            # directly take canonical output as the output_key.
            output_keys = (
                (
                    [self._canonical_output.key]
                    if self._canonical_output is not NOT_AVAILABLE
                    else []
                )
                if not self.conns.output_keys
                else self.conns.output_keys
            )
            # extract key mappings and data map of outer model
            key_mappings = self._generate_keys(
                include_internals=False, include_outputs=True
            )
            data_map = {key: conn.metadata.data for key, conn in self.conns.all.items()}

            for model, model_name in name_mappings.items():
                m_info = self.dag[model]
                # set default structure of conn_info and shape_info
                conns = conn_info.setdefault(model_name, ({}, {}))
                # include input keys with Tensor value
                input_keys = tuple(model._input_keys)
                # Generate sub_model key_map and data map
                model_key_map[model] = m_key_mappings = model._generate_keys(
                    include_internals=False, include_outputs=True
                )
                m_data_map = {
                    key: conn.metadata.data for key, conn in model.conns.all.items()
                }
                for inner_key in input_keys + tuple(model.conns.output_keys):
                    # Find the data of the key, if data memo is given, extract its
                    # copied version and extract the shapes
                    key_data = data_memo.get(
                        id(m_data_map[inner_key]), m_data_map[inner_key]
                    )

                    # Find inner and outer keys. Also find their updated version based
                    # on their key mappings
                    updated_inner_key = m_key_mappings.get(inner_key, inner_key)
                    outer_conn = m_info[inner_key]
                    outer_key = outer_conn.key
                    updated_outer_key = data_to_key_map.get(
                        key_data, [key_mappings.get(outer_key, outer_key)]
                    )

                    # take and setdefault connection list in which update will be done
                    conn = conns[inner_key in model.conns.output_keys].setdefault(
                        updated_inner_key, []
                    )
                    if inner_key not in input_keys:
                        continue

                    if (
                        isinstance(key_data, Scalar)
                        and (val := key_data.value) is not TBD
                    ):
                        conn.append(str(val))

                    elif outer_key in self._input_keys:
                        # If outer_key in input_keys of overall model, it means
                        # the input key is overall input to the model. Do the
                        # updates accordingly
                        input_name = ["'" + key + "'" for key in updated_outer_key]
                        conn.extend(input_name)
                    else:
                        # if input_key is not in self._input_keys, that means this
                        # input key connected to a model and it is an internal
                        # connection. Find the connected model and do the intializations
                        con_model = self.dependency_map._local_output_dependency_map[
                            outer_conn
                        ][0]
                        con_generated_keys = model_key_map.setdefault(
                            con_model,
                            con_model._generate_keys(
                                include_internals=False, include_outputs=True
                            ),
                        )
                        conn_info.setdefault(name_mappings[con_model], ({}, {}))
                        model_conn = m_info[inner_key]
                        con = con_model.conns.get_con_by_metadata(model_conn.metadata)
                        assert con is not None, "Connection is not found"
                        con_key = con.key

                        con_key = con_generated_keys.get(con_key, con_key)
                        # Since being internal key means having two sided connection,
                        # Two updates on conn_info dict needs to be done. one for
                        # model's input key and other for connected_model's output
                        # key. do the updates accordingly.
                        conn_info[model_name][0].setdefault(
                            updated_inner_key, []
                        ).append(name_mappings[con_model] + "." + con_key)
                        conn_info[name_mappings[con_model]][1].setdefault(
                            con_key, []
                        ).append(model_name + "." + updated_inner_key)

            for outer_key in output_keys:
                # Lastly, traverse through output keys of the overall model
                # Find the connected model, and find the inner key by finding
                # the metadata
                metadata = self.conns._get_metadata(outer_key)
                outer_out_conn = self.conns.get_connection(outer_key)

                assert metadata is not None, "Metadata is not found!"
                assert outer_out_conn is not None, "Connection is not found"

                model = self.dependency_map._local_output_dependency_map[
                    outer_out_conn
                ][0]
                other_conn = model.conns.get_con_by_metadata(metadata)
                assert other_conn is not None, "Connection is not found"

                inner_key = other_conn.key
                updated_inner_key = model_key_map[model].get(inner_key, inner_key)
                key_data = data_memo.get(id(data_map[outer_key]), data_map[outer_key])
                updated_outer_key = data_to_key_map.get(
                    key_data, [key_mappings.get(outer_key, outer_key)]
                )
                if updated_outer_key[0][0] == "$":
                    # There is only possibilty of outer key is found to be with $ sign.
                    # That is, if model is constructed with += operator. In that case,
                    # canonical output will be external key even if it is not named by
                    #  user. Therefore, handle the case with dicrectly writing $output
                    updated_outer_key = ["$output"]
                model_name = name_mappings[model]
                conn_info[model_name][1][updated_inner_key].extend(
                    ["'" + key + "'" for key in updated_outer_key]
                )

        return conn_info
